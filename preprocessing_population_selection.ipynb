{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_df = pd.read_csv(\"data/df_timeseries_en.tsv.gz\", sep='\\t', compression=\"gzip\", parse_dates=[\"datetime\"])\n",
    "timeseries_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_df = pd.read_csv(\"data/df_channels_en.tsv.gz\", sep='\\t', compression=\"gzip\")\n",
    "channel_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and fix metrics (change this description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_grouped_by_channel = timeseries_df.groupby('channel')\n",
    "\n",
    "# calculate cumulative views per channel\n",
    "timeseries_df[\"cumviews\"] = ts_grouped_by_channel[\"views\"].cumsum()\n",
    "\n",
    "# because negative delta views are not included in the original dataset, we recalculated them\n",
    "timeseries_df[\"delta_views\"] = ts_grouped_by_channel[\"views\"].diff().fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significative channels visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overnight success followed by downfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_channel = 'UCj-R_ePoJvWGiLOD6aDgMSg'\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(15, 10), sharex=True)\n",
    "axs_flat = axs.ravel()\n",
    "\n",
    "timeseries_df[timeseries_df[\"channel\"] == current_channel].plot(x=\"datetime\", y=\"cumviews\", ax=axs_flat[0])\n",
    "timeseries_df[timeseries_df[\"channel\"] == current_channel].plot(x=\"datetime\", y=\"views\", ax=axs_flat[1])\n",
    "timeseries_df[timeseries_df[\"channel\"] == current_channel].plot(x=\"datetime\", y=\"delta_views\", ax=axs_flat[2])\n",
    "\n",
    "for i in range(3):\n",
    "    axs_flat[i].legend(loc='upper left')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add explanation here to explain why this is a good example and what distinguishes it from the others, what are the features we are looking for, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overnight success followed by stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_channel = 'UCa4hfBXGDC_TxUHTEbCdyng'\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(15, 10), sharex=True)\n",
    "axs_flat = axs.ravel()\n",
    "\n",
    "timeseries_df[timeseries_df[\"channel\"] == current_channel].plot(x=\"datetime\", y=\"cumviews\", ax=axs_flat[0])\n",
    "timeseries_df[timeseries_df[\"channel\"] == current_channel].plot(x=\"datetime\", y=\"views\", ax=axs_flat[1])\n",
    "timeseries_df[timeseries_df[\"channel\"] == current_channel].plot(x=\"datetime\", y=\"delta_views\", ax=axs_flat[2])\n",
    "\n",
    "for i in range(3):\n",
    "    axs_flat[i].legend(loc='upper left')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add explanation here to explain why this is a good example and what distinguishes it from the others, what are the features we are looking for, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Population division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Calculate meaningful metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Metric 1: Views variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_views = ts_grouped_by_channel['views'].max()\n",
    "min_views = ts_grouped_by_channel['views'].min()\n",
    "\n",
    "variability = (max_views - min_views) / max_views\n",
    "channel_df[\"variability\"] = variability\n",
    "variability.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Metric 2: Channel growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin, end = ts_grouped_by_channel['views'].first(), ts_grouped_by_channel['views'].last()\n",
    "\n",
    "growth = (end - begin) / begin\n",
    "channel_df[\"growth\"] = growth\n",
    "growth.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Metric 3: Views growth steepness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_max = ts_grouped_by_channel[\"delta_views\"].max()\n",
    "\n",
    "growth_steepness = delta_max / max_views\n",
    "channel_df[\"growth_steepness\"] = growth_steepness\n",
    "growth_steepness.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame({\n",
    "    \"growth_steepness\": growth_steepness,\n",
    "    \"growth\": growth,\n",
    "    \"variability\": variability\n",
    "}).reset_index()\n",
    "metrics.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_df = channel_df.merge(metrics, on=\"channel\")\n",
    "channel_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Divide population using the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_bound = 0.2\n",
    "\n",
    "# select channels with a growth between -0.2 and 0.2\n",
    "lose_fame = channel_df[(-growth_bound < channel_df[\"growth\"]) & (channel_df[\"growth\"] < growth_bound)]\n",
    "\n",
    "# keep only channels with a growth greater than 0.2 because we're not interested in those who lost fame\n",
    "keep_fame = channel_df[channel_df[\"growth\"] > growth_bound]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial exploratory data analysis\n",
    "We added the metrics for further filtering but we still need to quantify the threshold.  \n",
    "Ideally we want to select channels with a high variability and a high growth steepness so ordering them by those metrics and selecting the top 10% should be a good start for an initial exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Further, and more accurate, filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.integrate as integrate\n",
    "\n",
    "def growth_rate_per_channel(df_timeseries):\n",
    "    sliding_window = 5\n",
    "\n",
    "    times = []\n",
    "    integrals = []\n",
    "    for i in range(len(df_timeseries['views']) - sliding_window):\n",
    "        window = df_timeseries['views'][i:i+sliding_window]\n",
    "        b, e = window.iloc[0], window.iloc[-1]\n",
    "\n",
    "        if e < b:\n",
    "            continue\n",
    "\n",
    "        line = np.array([(e - b) * j / (sliding_window - 1) + b for j in range(sliding_window)])\n",
    "\n",
    "        # since we are measuring the sudden increase in views as an integral of the difference between the linear increase and the actual increase,\n",
    "        # we have to make sure that the linear increase is above the actual increase at least at the beginning of the window\n",
    "        if window.iloc[1] > line[1]:\n",
    "            continue\n",
    "\n",
    "        if integrate.simpson(line - window) > 0:\n",
    "            # FIXME: add importance of the absolute value difference of values instead of only the area\n",
    "            integrals.append(integrate.simpson(np.abs(line - window)) / integrate.simpson(line))\n",
    "            times = times + [df_timeseries['datetime'].iloc[i]]\n",
    "\n",
    "    integrals = integrals + [0]\n",
    "    times = times + [df_timeseries['datetime'].iloc[0]]\n",
    "    \n",
    "    _max = np.argmax(integrals)\n",
    "    return pd.Series([times[_max], integrals[_max]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the sudden increase in views for each channel\n",
    "keep_fame_ts = timeseries_df[timeseries_df[\"channel\"].isin(keep_fame[\"channel\"])]\n",
    "keep_fame_sudden_growth = keep_fame_ts.groupby('channel').apply(growth_rate_per_channel).rename(columns={0: 'sudden_growth_date', 1: 'sudden_growth_index'})\n",
    "\n",
    "lose_fame_ts = timeseries_df[timeseries_df[\"channel\"].isin(lose_fame[\"channel\"])]\n",
    "lose_fame_sudden_growth = lose_fame_ts.groupby('channel').apply(growth_rate_per_channel).rename(columns={0: 'sudden_growth_date', 1: 'sudden_growth_index'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial exploratory data analysis\n",
    "Same as above, we want to analyze the channels comparing them by growth steepness, so further filtering using the new calculated metric should be done to additionally narrow the populations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ada_epfl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8553763fdcfc736a41f141ca3b864625738e1ec5c439d10ee554d8254e06fc6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
