{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video subcategories preprocessing and clustering\n",
    "To achieve a meaningful semantic clustering, we are using a pre-trained CLIP model to project the text features onto a 786-dimentional latent space using CLIP's causal language model. For this first phase, we are projecting the title and all the tags for each video as they're the most representative textual features available. With those projections, we obtain a point cloud for each video from which we compute a representative using a weighted average between the title and the tags point cloud.  \n",
    "In future steps we'll then proceed to perform PCA to reduce the dimensionality of the obtained projected data, and at last we'll apply a clustering algorithm to obtain the subcategories.\n",
    "\n",
    "To make the process faster, we are running the model on the GPU, so this notebook needs a pytorch version with cuda support and a GPU with VRAM >= 4GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>crawl_date</th>\n",
       "      <th>description</th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>display_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>like_count</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>view_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>2019-10-31 20:19:26.270363</td>\n",
       "      <td>Lego City Police Lego Firetruck Cartoons about...</td>\n",
       "      <td>1</td>\n",
       "      <td>SBqSc91Hn9g</td>\n",
       "      <td>1159</td>\n",
       "      <td>8</td>\n",
       "      <td>lego city,lego police,lego city police,lego ci...</td>\n",
       "      <td>Lego City Police Lego Firetruck Cartoons about...</td>\n",
       "      <td>2016-09-28 00:00:00</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>2019-10-31 20:19:26.914516</td>\n",
       "      <td>Lego Marvel SuperHeroes Lego Hulk Smash Iron-M...</td>\n",
       "      <td>1</td>\n",
       "      <td>UuugEl86ESY</td>\n",
       "      <td>2681</td>\n",
       "      <td>23</td>\n",
       "      <td>Lego superheroes,lego hulk,hulk smash,lego mar...</td>\n",
       "      <td>Lego Marvel SuperHeroes Lego Hulk Smash Iron-M...</td>\n",
       "      <td>2016-09-28 00:00:00</td>\n",
       "      <td>12894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         categories                channel_id                  crawl_date  \\\n",
       "0  Film & Animation  UCzWrhkg9eK5I8Bm3HfV-unA  2019-10-31 20:19:26.270363   \n",
       "1  Film & Animation  UCzWrhkg9eK5I8Bm3HfV-unA  2019-10-31 20:19:26.914516   \n",
       "\n",
       "                                         description  dislike_count  \\\n",
       "0  Lego City Police Lego Firetruck Cartoons about...              1   \n",
       "1  Lego Marvel SuperHeroes Lego Hulk Smash Iron-M...              1   \n",
       "\n",
       "    display_id  duration  like_count  \\\n",
       "0  SBqSc91Hn9g      1159           8   \n",
       "1  UuugEl86ESY      2681          23   \n",
       "\n",
       "                                                tags  \\\n",
       "0  lego city,lego police,lego city police,lego ci...   \n",
       "1  Lego superheroes,lego hulk,hulk smash,lego mar...   \n",
       "\n",
       "                                               title          upload_date  \\\n",
       "0  Lego City Police Lego Firetruck Cartoons about...  2016-09-28 00:00:00   \n",
       "1  Lego Marvel SuperHeroes Lego Hulk Smash Iron-M...  2016-09-28 00:00:00   \n",
       "\n",
       "   view_count  \n",
       "0        1057  \n",
       "1       12894  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data head for visualization\n",
    "data = pd.read_json('data/yt_metadata_en.jsonl.gz', compression='gzip', chunksize=20, lines=True)\n",
    "for chunk in data:\n",
    "    display(chunk.head(2))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained CLIP from transformers and move the model to the GPU\n",
    "\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import torch\n",
    "\n",
    "model_im = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "processor_im = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "model_im.to(torch.device('cuda'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `yt_metadata_en.jsonl.gz` file is very large and need to be processed in chunks. To make the computation interruptible with minimal impact, we split the results into several files (one per \"cpu chunk\"). Within those chunks, the data must be further divided into smaller subchunks to fit into the gpu memory. For each video in the \"gpu chunk\", we use the model to project its title and tags onto the latent space and proceed to compute the representative as described above. The approach of dividing the computation in \"cpu chunks\" allows us to deal with the dataset conveniently, stop the computation, and resume it from where it was interrupted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Processing chunk 173 (processed  1730000 rows)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Processing subchunk  566/10000 - memory allocated: 87.27461391044523% (3.49/4.00 GB)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import csv\n",
    "from math import log10, ceil\n",
    "import os\n",
    "import re\n",
    "\n",
    "files = sorted([int(re.search(\"[0-9]+\", x).group()) for x in os.listdir('features') if re.search(\"part_[0-9]+\\.csv$\", x)])\n",
    "start_index = files[-1] if len(files) > 0 else 0\n",
    "\n",
    "cpu_chunksize = 10000\n",
    "gpu_chunksize = 1\n",
    "tags_batch_size = 15\n",
    "\n",
    "tot_gpu_chunks = cpu_chunksize // gpu_chunksize\n",
    "assert type(tot_gpu_chunks) == int\n",
    "\n",
    "display_handle_cpu = display(\"\", display_id=True)\n",
    "display_handle_gpu = display(\"\", display_id=True)\n",
    "data = pd.read_json('data/yt_metadata_en.jsonl.gz', compression='gzip', chunksize=cpu_chunksize, lines=True, dtype={\"tags\": pd.StringDtype()})\n",
    "\n",
    "for i, cpu_chunk in enumerate(data):\n",
    "    display_handle_cpu.update(f\"Processing chunk {i+1:3d} (processed {cpu_chunksize*(i+1):8d} rows)\")\n",
    "\n",
    "    if i < start_index:\n",
    "        continue\n",
    "    \n",
    "    with open(f\"features/features_part_{i}.csv\", 'w', newline=\"\") as f_part:\n",
    "        part_writer = csv.writer(f_part)\n",
    "\n",
    "        for j in range(0, tot_gpu_chunks):\n",
    "            chunk = cpu_chunk.iloc[gpu_chunksize * j : gpu_chunksize * (j+1)].copy().reset_index(drop=True)\n",
    "            \n",
    "            allocated, tot = torch.cuda.mem_get_info()\n",
    "            display_handle_gpu.update(f\"Processing subchunk {j+1:{int(ceil(log10(tot_gpu_chunks)))}d}/{tot_gpu_chunks} - memory allocated: {(tot - allocated) / tot * 100}% ({(tot - allocated) / 1024 / 1024 / 1024:.2f}/{tot / 1024 / 1024 / 1024:.2f} GB)\")\n",
    "\n",
    "            def get_features(x):\n",
    "                encoded = processor_im(text=x, padding=True, truncation=True, return_tensors=\"pt\").to('cuda')\n",
    "                result = model_im.get_text_features(**encoded)\n",
    "                cpu_result = result\n",
    "                del encoded\n",
    "                del result\n",
    "                return cpu_result.detach()\n",
    "\n",
    "            title_features = get_features(chunk['title'].str[:77].to_list())\n",
    "\n",
    "            tag_series = chunk['tags'].str.split(\",\").apply(lambda xs: [x.strip()[:77] for x in xs])\n",
    "            tags_features = torch.stack([torch.mean(torch.cat([get_features(video_tags[i*tags_batch_size:(i+1)*tags_batch_size]).cpu() for i in range(ceil(len(video_tags)/tags_batch_size))], dim=0), dim=0) for video_tags in tag_series])\n",
    "\n",
    "            text_features = 0.6 * title_features.cpu() + 0.4 * tags_features\n",
    "            text_features_numpy = text_features.cpu().detach().numpy()\n",
    "            \n",
    "            part_writer.writerows(text_features_numpy)\n",
    "\n",
    "            del title_features\n",
    "            del tags_features\n",
    "            del text_features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ada_epfl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8553763fdcfc736a41f141ca3b864625738e1ec5c439d10ee554d8254e06fc6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
